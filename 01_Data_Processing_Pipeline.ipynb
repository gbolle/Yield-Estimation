{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telangana Crop Yield Prediction - Data Processing Pipeline\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the complete data processing pipeline for Telangana crop yield prediction system.\n",
    "\n",
    "### What You'll Learn:\n",
    "1. Loading crop and weather datasets\n",
    "2. Data cleaning and preprocessing\n",
    "3. Feature engineering for agricultural predictions\n",
    "4. Merging multiple data sources\n",
    "5. Creating the final training dataset\n",
    "\n",
    "### Dataset Information:\n",
    "- **Crop Data**: 32 crops across 32 districts (2018-2022)\n",
    "- **Weather Data**: Daily rainfall, temperature, humidity (47+ months)\n",
    "- **Final Dataset**: 5,621 records with 25+ features\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "We'll use:\n",
    "- **pandas**: Data manipulation and analysis\n",
    "- **numpy**: Numerical computations\n",
    "- **matplotlib/seaborn**: Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(f\"   Pandas version: {pd.__version__}\")\n",
    "print(f\"   NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Crop Data\n",
    "\n",
    "### About the Crop Dataset:\n",
    "- Contains agricultural production data for Telangana\n",
    "- Covers 32 different crops\n",
    "- Spans across 32 districts and multiple years\n",
    "- Includes: District, Season, Crop, Year, Area, Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load crop data\n",
    "crop_df = pd.read_csv('Telangana_AgriData_Suite/sample_data/telangana_crop_data_cleaned.csv')\n",
    "\n",
    "print(\"📊 Crop Dataset Loaded!\")\n",
    "print(f\"   Total Records: {len(crop_df):,}\")\n",
    "print(f\"   Columns: {list(crop_df.columns)}\")\n",
    "print(f\"\\n   Shape: {crop_df.shape}\")\n",
    "\n",
    "# Display first few records\n",
    "print(\"\\n📋 Sample Data:\")\n",
    "crop_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration: Crop Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"📊 Dataset Information:\")\n",
    "print(f\"   Unique Districts: {crop_df['District'].nunique()}\")\n",
    "print(f\"   Unique Crops: {crop_df['Crop'].nunique()}\")\n",
    "print(f\"   Unique Seasons: {crop_df['Season'].nunique()}\")\n",
    "print(f\"   Year Range: {crop_df['Year'].min()} - {crop_df['Year'].max()}\")\n",
    "\n",
    "print(\"\\n🌾 Available Crops:\")\n",
    "print(crop_df['Crop'].unique())\n",
    "\n",
    "print(\"\\n🏘️ Available Districts:\")\n",
    "print(sorted(crop_df['District'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Yield (Target Variable)\n",
    "\n",
    "**Formula**: Yield (kg/ha) = (Production in tons × 1000) / Area in hectares\n",
    "\n",
    "This is our **target variable** that we want to predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate yield in kg/ha\n",
    "# Multiply by 1000 to convert from tons to kg\n",
    "crop_df['Yield'] = (crop_df['Production'] / crop_df['Area']) * 1000\n",
    "\n",
    "# Handle infinite and NaN values\n",
    "crop_df['Yield'] = crop_df['Yield'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "print(\"✅ Yield Calculated!\")\n",
    "print(f\"\\n📊 Yield Statistics (kg/ha):\")\n",
    "print(crop_df['Yield'].describe())\n",
    "\n",
    "# Visualize yield distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "crop_df['Yield'].hist(bins=50, edgecolor='black')\n",
    "plt.xlabel('Yield (kg/ha)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Crop Yields')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "crop_df.boxplot(column='Yield', by='Season', figsize=(6, 5))\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Yield (kg/ha)')\n",
    "plt.title('Yield by Season')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Weather Data\n",
    "\n",
    "### About the Weather Dataset:\n",
    "- Daily weather observations (47+ months)\n",
    "- Parameters: Rainfall, Temperature (Min/Max), Humidity (Min/Max)\n",
    "- Aggregated to seasonal level (Kharif: Jun-Oct, Rabi: Nov-Mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rainfall/weather data\n",
    "weather_df = pd.read_csv('Telangana_AgriData_Suite/sample_data/telangana_rainfall_seasonal.csv')\n",
    "\n",
    "print(\"🌦️ Weather Dataset Loaded!\")\n",
    "print(f\"   Total Records: {len(weather_df):,}\")\n",
    "print(f\"   Columns: {list(weather_df.columns)}\")\n",
    "print(f\"\\n   Shape: {weather_df.shape}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\n📋 Sample Weather Data:\")\n",
    "weather_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather statistics\n",
    "print(\"📊 Weather Statistics:\")\n",
    "print(f\"   Districts with weather data: {weather_df['District'].nunique()}\")\n",
    "print(f\"   Seasons: {weather_df['Season'].unique()}\")\n",
    "print(f\"   Year Range: {weather_df['Year'].min()} - {weather_df['Year'].max()}\")\n",
    "\n",
    "print(\"\\n🌧️ Rainfall Statistics (mm):\")\n",
    "print(weather_df['Total_Rainfall'].describe())\n",
    "\n",
    "print(\"\\n🌡️ Temperature Statistics (°C):\")\n",
    "print(\"   Avg Min Temp:\", weather_df['Avg_Temp_Min'].describe())\n",
    "print(\"   Avg Max Temp:\", weather_df['Avg_Temp_Max'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Merge Crop and Weather Data\n",
    "\n",
    "### Merging Strategy:\n",
    "- Join on: **District, Season, Year**\n",
    "- This links crop performance to corresponding weather conditions\n",
    "- Enables weather-driven yield predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge crop and weather data\n",
    "print(\"🔗 Merging crop and weather datasets...\")\n",
    "print(f\"   Crop records before merge: {len(crop_df):,}\")\n",
    "print(f\"   Weather records: {len(weather_df):,}\")\n",
    "\n",
    "# Perform merge\n",
    "merged_df = crop_df.merge(\n",
    "    weather_df,\n",
    "    on=['District', 'Season', 'Year'],\n",
    "    how='inner'  # Keep only matching records\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Merge Complete!\")\n",
    "print(f\"   Final records: {len(merged_df):,}\")\n",
    "print(f\"   Total features: {len(merged_df.columns)}\")\n",
    "print(f\"\\n   Districts in final dataset: {merged_df['District'].nunique()}\")\n",
    "\n",
    "# Check for data quality\n",
    "print(f\"\\n📊 Data Quality Check:\")\n",
    "print(f\"   Missing values:\\n{merged_df.isnull().sum()[merged_df.isnull().sum() > 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Feature Engineering\n",
    "\n",
    "### Creating Advanced Features:\n",
    "We'll create domain-specific features that help the model learn better:\n",
    "\n",
    "1. **Temporal Features**: Years since start\n",
    "2. **Weather Derivatives**: Average temp, temp range, rainfall per day\n",
    "3. **Agricultural Indicators**: GDD (Growing Degree Days)\n",
    "4. **Stress Indicators**: Heat stress, water stress\n",
    "5. **Interaction Features**: Area × Rainfall, Area × Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔧 Engineering Features...\\n\")\n",
    "\n",
    "# 1. Temporal Feature\n",
    "merged_df['Years_Since_Start'] = merged_df['Year'] - merged_df['Year'].min()\n",
    "print(\"✅ Created: Years_Since_Start\")\n",
    "\n",
    "# 2. Rainfall-based features\n",
    "# Days in season (Kharif: 153 days, Rabi: 151 days)\n",
    "merged_df['Season_Days'] = merged_df['Season'].map({'Kharif': 153, 'Rabi': 151})\n",
    "merged_df['Rainfall_Per_Day'] = merged_df['Total_Rainfall'] / merged_df['Season_Days']\n",
    "print(\"✅ Created: Rainfall_Per_Day\")\n",
    "\n",
    "# 3. Temperature features\n",
    "merged_df['Temp_Avg'] = (merged_df['Avg_Temp_Min'] + merged_df['Avg_Temp_Max']) / 2\n",
    "merged_df['Temp_Range'] = merged_df['Avg_Temp_Max'] - merged_df['Avg_Temp_Min']\n",
    "print(\"✅ Created: Temp_Avg, Temp_Range\")\n",
    "\n",
    "# 4. Humidity features\n",
    "merged_df['Humidity_Avg'] = (merged_df['Avg_Humidity_Min'] + merged_df['Avg_Humidity_Max']) / 2\n",
    "merged_df['Humidity_Range'] = merged_df['Avg_Humidity_Max'] - merged_df['Avg_Humidity_Min']\n",
    "print(\"✅ Created: Humidity_Avg, Humidity_Range\")\n",
    "\n",
    "# 5. Growing Degree Days (GDD)\n",
    "# Formula: max(0, Temp_Avg - Base_Temp)\n",
    "# Base temperature for crops (typically 10°C)\n",
    "base_temp = 10\n",
    "merged_df['GDD'] = merged_df['Temp_Avg'].apply(lambda x: max(0, x - base_temp))\n",
    "print(\"✅ Created: GDD (Growing Degree Days)\")\n",
    "\n",
    "# 6. Stress Indicators\n",
    "# Heat Stress: Temperature above 35°C is stressful\n",
    "merged_df['Heat_Stress'] = (merged_df['Avg_Temp_Max'] > 35).astype(int)\n",
    "\n",
    "# Water Stress: Rainfall below 500mm is stressful\n",
    "merged_df['Water_Stress'] = (merged_df['Total_Rainfall'] < 500).astype(int)\n",
    "\n",
    "# Optimal Conditions: No stress\n",
    "merged_df['Optimal_Conditions'] = ((merged_df['Heat_Stress'] == 0) & \n",
    "                                    (merged_df['Water_Stress'] == 0)).astype(int)\n",
    "print(\"✅ Created: Heat_Stress, Water_Stress, Optimal_Conditions\")\n",
    "\n",
    "# 7. Interaction Features\n",
    "# These capture combined effects\n",
    "merged_df['Area_Rainfall_Interaction'] = merged_df['Area'] * merged_df['Total_Rainfall']\n",
    "merged_df['Area_Temp_Interaction'] = merged_df['Area'] * merged_df['Temp_Avg']\n",
    "print(\"✅ Created: Area_Rainfall_Interaction, Area_Temp_Interaction\")\n",
    "\n",
    "print(f\"\\n🎉 Feature Engineering Complete!\")\n",
    "print(f\"   Total features now: {len(merged_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key engineered features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# GDD distribution\n",
    "axes[0, 0].hist(merged_df['GDD'], bins=30, edgecolor='black', color='skyblue')\n",
    "axes[0, 0].set_title('Growing Degree Days (GDD)')\n",
    "axes[0, 0].set_xlabel('GDD')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Rainfall per day\n",
    "axes[0, 1].hist(merged_df['Rainfall_Per_Day'], bins=30, edgecolor='black', color='lightgreen')\n",
    "axes[0, 1].set_title('Daily Rainfall')\n",
    "axes[0, 1].set_xlabel('Rainfall (mm/day)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Temperature range\n",
    "axes[0, 2].hist(merged_df['Temp_Range'], bins=30, edgecolor='black', color='coral')\n",
    "axes[0, 2].set_title('Temperature Range')\n",
    "axes[0, 2].set_xlabel('Range (°C)')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# Stress indicators\n",
    "stress_counts = pd.DataFrame({\n",
    "    'Heat Stress': merged_df['Heat_Stress'].value_counts(),\n",
    "    'Water Stress': merged_df['Water_Stress'].value_counts(),\n",
    "    'Optimal': merged_df['Optimal_Conditions'].value_counts()\n",
    "})\n",
    "stress_counts.plot(kind='bar', ax=axes[1, 0], color=['red', 'blue', 'green'])\n",
    "axes[1, 0].set_title('Stress Indicators')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_xticklabels(['No', 'Yes'], rotation=0)\n",
    "\n",
    "# Yield vs GDD\n",
    "axes[1, 1].scatter(merged_df['GDD'], merged_df['Yield'], alpha=0.5, s=10)\n",
    "axes[1, 1].set_title('Yield vs Growing Degree Days')\n",
    "axes[1, 1].set_xlabel('GDD')\n",
    "axes[1, 1].set_ylabel('Yield (kg/ha)')\n",
    "\n",
    "# Yield vs Rainfall\n",
    "axes[1, 2].scatter(merged_df['Total_Rainfall'], merged_df['Yield'], alpha=0.5, s=10, color='green')\n",
    "axes[1, 2].set_title('Yield vs Total Rainfall')\n",
    "axes[1, 2].set_xlabel('Rainfall (mm)')\n",
    "axes[1, 2].set_ylabel('Yield (kg/ha)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Processed Dataset\n",
    "\n",
    "We'll save the fully processed dataset for use in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed dataset\n",
    "output_file = 'telangana_complete_processed.csv'\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Dataset Saved: {output_file}\")\n",
    "print(f\"\\n📊 Final Dataset Summary:\")\n",
    "print(f\"   Total Records: {len(merged_df):,}\")\n",
    "print(f\"   Total Features: {len(merged_df.columns)}\")\n",
    "print(f\"   Districts: {merged_df['District'].nunique()}\")\n",
    "print(f\"   Crops: {merged_df['Crop'].nunique()}\")\n",
    "print(f\"   Year Range: {merged_df['Year'].min()} - {merged_df['Year'].max()}\")\n",
    "print(f\"\\n   File Size: {merged_df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Display final columns\n",
    "print(f\"\\n📋 Final Columns:\")\n",
    "for i, col in enumerate(merged_df.columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "✅ Loaded crop and weather datasets\n",
    "\n",
    "✅ Calculated yield (target variable)\n",
    "\n",
    "✅ Merged data sources on District, Season, Year\n",
    "\n",
    "✅ Engineered 15+ domain-specific features\n",
    "\n",
    "✅ Created comprehensive training dataset\n",
    "\n",
    "✅ Saved processed data for ML modeling\n",
    "\n",
    "### Key Features Created:\n",
    "- **Weather**: Total_Rainfall, Rainfall_Per_Day, Temp_Avg, Temp_Range, Humidity_Avg\n",
    "- **Agricultural**: GDD, Heat_Stress, Water_Stress, Optimal_Conditions\n",
    "- **Interactions**: Area_Rainfall_Interaction, Area_Temp_Interaction\n",
    "\n",
    "### Next Step:\n",
    "Move to **02_ML_Model_Training.ipynb** to build and train the prediction model!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
